{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2044bcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "140bc545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import csv's for analysis\n",
    "user_df = pd.read_csv(\"Original_Files/USER_TAKEHOME.csv\")\n",
    "transaction_df = pd.read_csv(\"Original_Files/TRANSACTION_TAKEHOME.csv\")\n",
    "products_df = pd.read_csv(\"Original_Files/PRODUCTS_TAKEHOME.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c685e741",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'CREATED_DATE', 'BIRTH_DATE', 'STATE', 'LANGUAGE', 'GENDER'], dtype='object')\n",
      "Index(['RECEIPT_ID', 'PURCHASE_DATE', 'SCAN_DATE', 'STORE_NAME', 'USER_ID',\n",
      "       'BARCODE', 'FINAL_QUANTITY', 'FINAL_SALE'],\n",
      "      dtype='object')\n",
      "Index(['CATEGORY_1', 'CATEGORY_2', 'CATEGORY_3', 'CATEGORY_4', 'MANUFACTURER',\n",
      "       'BRAND', 'BARCODE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print all DataFrames to see columns for each CSV\n",
    "print(user_df.columns)\n",
    "print(transaction_df.columns)\n",
    "print(products_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eb759a",
   "metadata": {},
   "source": [
    "## Reviewng data for any null values for database import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33b9d9a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_DF\n",
      "ID                  0\n",
      "CREATED_DATE        0\n",
      "BIRTH_DATE       3675\n",
      "STATE            4812\n",
      "LANGUAGE        30508\n",
      "GENDER           5892\n",
      "dtype: int64\n",
      "\n",
      "Transaction_DF\n",
      "RECEIPT_ID           0\n",
      "PURCHASE_DATE        0\n",
      "SCAN_DATE            0\n",
      "STORE_NAME           0\n",
      "USER_ID              0\n",
      "BARCODE           5762\n",
      "FINAL_QUANTITY       0\n",
      "FINAL_SALE           0\n",
      "dtype: int64\n",
      "\n",
      "Products_DF\n",
      "CATEGORY_1         111\n",
      "CATEGORY_2        1424\n",
      "CATEGORY_3       60566\n",
      "CATEGORY_4      778093\n",
      "MANUFACTURER    226474\n",
      "BRAND           226472\n",
      "BARCODE           4025\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "##Identify any null values for each csv to determine primary/foreign keys or major anomolies\n",
    "print(\"User_DF\\n\"+ str(user_df.isnull().sum()))\n",
    "print(\"\\nTransaction_DF\\n\"+ str(transaction_df.isnull().sum()))\n",
    "print(\"\\nProducts_DF\\n\"+ str(products_df.isnull().sum())) \n",
    "## Due to Products having no columns with no missing values will propose to include index on exported CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797d0fc2",
   "metadata": {},
   "source": [
    "### Review datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b3f0fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_DF\n",
      "ID              object\n",
      "CREATED_DATE    object\n",
      "BIRTH_DATE      object\n",
      "STATE           object\n",
      "LANGUAGE        object\n",
      "GENDER          object\n",
      "dtype: object\n",
      "\n",
      "Transaction_DF\n",
      "RECEIPT_ID         object\n",
      "PURCHASE_DATE      object\n",
      "SCAN_DATE          object\n",
      "STORE_NAME         object\n",
      "USER_ID            object\n",
      "BARCODE           float64\n",
      "FINAL_QUANTITY     object\n",
      "FINAL_SALE         object\n",
      "dtype: object\n",
      "\n",
      "Products_DF\n",
      "CATEGORY_1       object\n",
      "CATEGORY_2       object\n",
      "CATEGORY_3       object\n",
      "CATEGORY_4       object\n",
      "MANUFACTURER     object\n",
      "BRAND            object\n",
      "BARCODE         float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"User_DF\\n\"+ str(user_df.dtypes))\n",
    "print(\"\\nTransaction_DF\\n\"+ str(transaction_df.dtypes))\n",
    "print(\"\\nProducts_DF\\n\"+ str(products_df.dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fc4c2b",
   "metadata": {},
   "source": [
    "### Date conversions to YYYY-MM-DD Format to align all date fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ce34aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                CREATED_DATE                 BIRTH_DATE\n",
      "0  2020-06-24 20:17:54.000 Z  2000-08-11 00:00:00.000 Z\n",
      "1  2021-01-03 19:53:55.000 Z  2001-09-24 04:00:00.000 Z\n",
      "2  2023-05-31 18:42:18.000 Z  1994-10-28 00:00:00.000 Z\n",
      "3  2023-12-26 01:46:22.000 Z                        NaN\n",
      "4  2023-10-28 11:51:50.000 Z  1972-03-19 00:00:00.000 Z\n",
      "\n",
      "  PURCHASE_DATE                  SCAN_DATE\n",
      "0    2024-08-21  2024-08-21 14:19:06.539 Z\n",
      "1    2024-07-20  2024-07-20 09:50:24.206 Z\n",
      "2    2024-08-18  2024-08-19 15:38:56.813 Z\n",
      "3    2024-06-18  2024-06-19 11:03:37.468 Z\n",
      "4    2024-07-04  2024-07-05 15:56:43.549 Z\n"
     ]
    }
   ],
   "source": [
    "#review dates and multiple types found (datetime & YYYY-MM-DD)\n",
    "print(user_df[['CREATED_DATE', 'BIRTH_DATE']].head())\n",
    "print(\"\\n\" + str(transaction_df[['PURCHASE_DATE', 'SCAN_DATE']].head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75172d44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CREATED_DATE    datetime64[ns]\n",
       "BIRTH_DATE      datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Updating user_df & transaction_df object types to datetime for conversion to simplier date format\n",
    "user_df[['CREATED_DATE', 'BIRTH_DATE']] = user_df[['CREATED_DATE', 'BIRTH_DATE']].astype('datetime64')\n",
    "transaction_df['SCAN_DATE'] = transaction_df['SCAN_DATE'].astype('datetime64')\n",
    "\n",
    "#validation of update\n",
    "user_df[['CREATED_DATE', 'BIRTH_DATE']].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40777ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CREATED_DATE  BIRTH_DATE\n",
      "0   2020-06-24  2000-08-11\n",
      "1   2021-01-03  2001-09-24\n",
      "2   2023-05-31  1994-10-28\n",
      "3   2023-12-26         NaN\n",
      "4   2023-10-28  1972-03-19\n",
      "\n",
      "  PURCHASE_DATE   SCAN_DATE\n",
      "0    2024-08-21  2024-08-21\n",
      "1    2024-07-20  2024-07-20\n",
      "2    2024-08-18  2024-08-19\n",
      "3    2024-06-18  2024-06-19\n",
      "4    2024-07-04  2024-07-05\n"
     ]
    }
   ],
   "source": [
    "#Converting datetime dates to YYYY-MM-DD formatting\n",
    "## User_Df update (errors='coerce' in case of null value ignores and moves on with the update as we want to keep nulls)\n",
    "user_df['CREATED_DATE'] = pd.to_datetime(user_df['CREATED_DATE'], format='%Y-%m-%d', errors='coerce')\n",
    "user_df['CREATED_DATE'] = user_df['CREATED_DATE'].dt.strftime('%Y-%m-%d')\n",
    "user_df['BIRTH_DATE'] = pd.to_datetime(user_df['BIRTH_DATE'], format='%Y-%m-%d', errors='coerce')\n",
    "user_df['BIRTH_DATE'] = user_df['BIRTH_DATE'].dt.strftime('%Y-%m-%d')\n",
    "## transaction_df update\n",
    "transaction_df['SCAN_DATE'] = pd.to_datetime(transaction_df['SCAN_DATE'], format='%Y-%m-%d', errors='coerce')\n",
    "transaction_df['SCAN_DATE'] = transaction_df['SCAN_DATE'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "#Validation of updates\n",
    "print(user_df[['CREATED_DATE', 'BIRTH_DATE']].head())\n",
    "print(\"\\n\" + str(transaction_df[['PURCHASE_DATE', 'SCAN_DATE']].head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbb58c4",
   "metadata": {},
   "source": [
    "#### Data Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca637d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1.00', 'zero', '2.00', '3.00', '4.00', '4.55', '2.83', '2.34',\n",
       "       '0.46', '7.00', '18.00', '12.00', '5.00', '2.17', '0.23', '8.00',\n",
       "       '1.35', '0.09', '2.58', '1.47', '16.00', '0.62', '1.24', '1.40',\n",
       "       '0.51', '0.53', '1.69', '6.00', '2.39', '2.60', '10.00', '0.86',\n",
       "       '1.54', '1.88', '2.93', '1.28', '0.65', '2.89', '1.44', '2.75',\n",
       "       '1.81', '276.00', '0.87', '2.10', '3.33', '2.54', '2.20', '1.93',\n",
       "       '1.34', '1.13', '2.19', '0.83', '2.61', '0.28', '1.50', '0.97',\n",
       "       '0.24', '1.18', '6.22', '1.22', '1.23', '2.57', '1.07', '2.11',\n",
       "       '0.48', '9.00', '3.11', '1.08', '5.53', '1.89', '0.01', '2.18',\n",
       "       '1.99', '0.04', '2.25', '1.37', '3.02', '0.35', '0.99', '1.80',\n",
       "       '3.24', '0.94', '2.04', '3.69', '0.70', '2.52', '2.27'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##review final quantity as 'zero' found within dataset\n",
    "transaction_df['FINAL_QUANTITY'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eab1abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update 'zero' to '0' kept same formating when input into sql will update to float value\n",
    "transaction_df.loc[transaction_df['FINAL_QUANTITY'] == 'zero', 'FINAL_QUANTITY'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3594329",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1.00', '0', '2.00', '3.00', '4.00', '4.55', '2.83', '2.34',\n",
       "       '0.46', '7.00', '18.00', '12.00', '5.00', '2.17', '0.23', '8.00',\n",
       "       '1.35', '0.09', '2.58', '1.47', '16.00', '0.62', '1.24', '1.40',\n",
       "       '0.51', '0.53', '1.69', '6.00', '2.39', '2.60', '10.00', '0.86',\n",
       "       '1.54', '1.88', '2.93', '1.28', '0.65', '2.89', '1.44', '2.75',\n",
       "       '1.81', '276.00', '0.87', '2.10', '3.33', '2.54', '2.20', '1.93',\n",
       "       '1.34', '1.13', '2.19', '0.83', '2.61', '0.28', '1.50', '0.97',\n",
       "       '0.24', '1.18', '6.22', '1.22', '1.23', '2.57', '1.07', '2.11',\n",
       "       '0.48', '9.00', '3.11', '1.08', '5.53', '1.89', '0.01', '2.18',\n",
       "       '1.99', '0.04', '2.25', '1.37', '3.02', '0.35', '0.99', '1.80',\n",
       "       '3.24', '0.94', '2.04', '3.69', '0.70', '2.52', '2.27'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##validation of update\n",
    "transaction_df['FINAL_QUANTITY'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb785a2",
   "metadata": {},
   "source": [
    "#### Update Hidden valley ranch convert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce78b8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df['BRAND'] = products_df['BRAND'].replace(\"Hidden Valley\", \"Hidden Valley Ranch\")\n",
    "products_df['MANUFACTURER'] = products_df['MANUFACTURER'].replace(\"CLOROX NATIONAL\", \"THE CLOROX COMPANY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a81e291",
   "metadata": {},
   "source": [
    "#### Update Barcode to remove .0 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48a52642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove '.0' from the end of the string in 'BARCODE' column\n",
    "# Assuming transaction_df is your DataFrame\n",
    "transaction_df['BARCODE'] = pd.to_numeric(transaction_df['BARCODE'], errors='coerce')  # This will convert to NaN if not a number\n",
    "transaction_df['BARCODE'] = transaction_df['BARCODE'].astype(str).str.replace(r'\\.0$', '', regex=True)\n",
    "# transaction_df['BARCODE'] = transaction_df['BARCODE'].astype('Int64')  # Converts to nullable Int64 type, which supports NaN\n",
    "transaction_df['BARCODE'] = transaction_df['BARCODE'].replace('nan', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58615cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove '.0' from the end of the string in 'BARCODE' column\n",
    "# Assuming transaction_df is your DataFrame\n",
    "products_df['BARCODE'] = pd.to_numeric(products_df['BARCODE'], errors='coerce')  # This will convert to NaN if not a number\n",
    "products_df['BARCODE'] = products_df['BARCODE'].astype(str).str.replace(r'\\.0$', '', regex=True)\n",
    "# transaction_df['BARCODE'] = transaction_df['BARCODE'].astype('Int64')  # Converts to nullable Int64 type, which supports NaN\n",
    "products_df['BARCODE'] = products_df['BARCODE'].replace('nan', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44057750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating values to numeric for SQL Import\n",
    "transaction_df['FINAL_SALE'] = pd.to_numeric(transaction_df['FINAL_SALE'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897635f0",
   "metadata": {},
   "source": [
    "### Save csv's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd8d5ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.to_csv('user_df.csv',index = False)\n",
    "transaction_df.to_csv('transaction_df.csv',index = True)\n",
    "products_df.to_csv('products_df.csv',index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
